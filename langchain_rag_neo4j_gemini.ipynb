{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Eager\n",
        "!pip install graph-retriever\n",
        "!pip install langchain-google-genai\n",
        "!pip install langchain_experimental\n",
        "!pip install langchain_neo4j\n",
        "!pip install langchain_graph_retriever\n",
        "!pip install docx2txt"
      ],
      "metadata": {
        "id": "BpQkbeivRtbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from typing import List\n",
        "from langchain_core.documents import Document\n",
        "from graph_retriever.strategies import Eager\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "from langchain_graph_retriever import GraphRetriever# Initialize LLM Graph Transformer\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#from google.colab import userdata\n",
        "#google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "google_api_key=\"AIzaSyDZ1PBvZSNKPg6NYLNAH6qxsjx4ga2OHms\"\n",
        "\n"
      ],
      "metadata": {
        "id": "2-wUh2XXRJn6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_chunk_documents() -> List[Document]:\n",
        "    \"\"\"Load and chunk .docx files using semantic chunking\"\"\"\n",
        "    documents = []\n",
        "    docx_files = glob.glob(r\"C:\\Users\\0J0795897\\pythonAI\\*.docx\")  # Adjust path as needed\n",
        "\n",
        "    if not docx_files:\n",
        "        print(\"No .docx files found\")\n",
        "        return documents\n",
        "\n",
        "    # Initialize semantic chunker\n",
        "    text_splitter = SemanticChunker(embeddings)\n",
        "\n",
        "    for docx_file in docx_files:\n",
        "        print(f\"Processing {docx_file}...\")\n",
        "\n",
        "        # Load document\n",
        "        loader = Docx2txtLoader(docx_file)\n",
        "        raw_docs = loader.load()\n",
        "\n",
        "        # Apply semantic chunking\n",
        "        chunks = text_splitter.split_documents(raw_docs)\n",
        "\n",
        "        # Add metadata\n",
        "        for chunk in chunks:\n",
        "            chunk.metadata[\"source\"] = os.path.basename(docx_file)\n",
        "\n",
        "        documents.extend(chunks)\n",
        "\n",
        "    print(f\"pyLoaded {len(documents)} document chunks\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "YO7c7zTzQn95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_graph_documents(graph_documents: List):\n",
        "    \"\"\"Store graph documents in Neo4j\"\"\"\n",
        "    print(\"Storing graph data in Neo4j...\")\n",
        "\n",
        "    # Clear existing data (optional)\n",
        "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
        "\n",
        "    for graph_doc in graph_documents:\n",
        "        # Add nodes\n",
        "        for node in graph_doc.nodes:\n",
        "            node_type = node.type.replace(\" \", \"_\")  # Sanitize for Neo4j\n",
        "            graph.query(\n",
        "                f\"MERGE (n:{node_type} {{id: $id}})\",\n",
        "                {\"id\": node.id}\n",
        "            )\n",
        "\n",
        "        # Add relationships\n",
        "        for rel in graph_doc.relationships:\n",
        "            rel_type = rel.type.replace(\" \", \"_\")\n",
        "            graph.query(\n",
        "                f\"\"\"\n",
        "                MATCH (source {{id: $source_id}})\n",
        "                MATCH (target {{id: $target_id}})\n",
        "                MERGE (source)-[r:{rel_type}]->(target)\n",
        "                \"\"\",\n",
        "                {\n",
        "                    \"source_id\": rel.source.id,\n",
        "                    \"target_id\": rel.target.id\n",
        "                }\n",
        "            )\n",
        "\n",
        "    print(\"Graph data stored successfully\")"
      ],
      "metadata": {
        "id": "LBuONbXkQ1Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rag_chain(vector_store):\n",
        "    \"\"\"Create RAG chain with graph and vector retrieval\"\"\"\n",
        "    # Create a strategy based on your data\n",
        "    traversal_config = Eager(\n",
        "        select_k=5,\n",
        "        start_k=2,\n",
        "        adjacent_k=3,\n",
        "        max_depth=2\n",
        "    )\n",
        "\n",
        "    # Create graph retriever\n",
        "    graph_retriever = GraphRetriever(\n",
        "        store=vector_store,\n",
        "        strategy=traversal_config,\n",
        "    )\n",
        "\n",
        "    # Document formatter\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Prompt template\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "    Answer the question based on the provided context.\n",
        "\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\")\n",
        "\n",
        "    # Create chain\n",
        "    chain = (\n",
        "        {\n",
        "            \"context\": graph_retriever | format_docs,\n",
        "            \"question\": RunnablePassthrough()\n",
        "        }\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "NdU59vGoQ5rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_graphrag_system(chain):\n",
        "    \"\"\"Test the GraphRAG system with sample queries\"\"\"\n",
        "\n",
        "    test_queries = [\n",
        "        \"What are the main topics discussed in the documents?\",\n",
        "        \"How are the entities connected in the knowledge graph?\",\n",
        "        \"Can you explain the relationships between key concepts?\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\n🔍 Query: {query}\")\n",
        "        try:\n",
        "            response = chain.invoke(query)\n",
        "            print(f\"Response: {response[:200]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    # Check graph statistics\n",
        "    try:\n",
        "        nodes_count = graph.query(\"MATCH (n) RETURN count(n) as count\")[0][\"count\"]\n",
        "        rels_count = graph.query(\"MATCH ()-[r]->() RETURN count(r) as count\")[0][\"count\"]\n",
        "        print(f\"\\nGraph Stats: {nodes_count} nodes, {rels_count} relationships\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting graph stats: {e}\")\n"
      ],
      "metadata": {
        "id": "sHBTUmA9Q9UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2kE3yvrP2hm"
      },
      "outputs": [],
      "source": [
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-exp-03-07\",\n",
        "    google_api_key=google_api_key\n",
        ")\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.5-flash-preview-05-20\",\n",
        "    google_api_key=google_api_key\n",
        ")\n",
        "graph = Neo4jGraph(\n",
        "    url=\"bolt://localhost:7687\",\n",
        "    username=\"neo4j\",\n",
        "    password=\"changeit\"\n",
        ")\n",
        "print(\"Initializing LLM Graph Transformer...\")\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)# Initialize components\n",
        "\n",
        "def main():\n",
        "    \"\"\"Complete GraphRAG implementation\"\"\"\n",
        "    print(\"Starting GraphRAG System\")\n",
        "\n",
        "    # 1. Load and chunk documents\n",
        "    documents = load_and_chunk_documents()\n",
        "\n",
        "    # 2. Create vector store\n",
        "    vector_store = InMemoryVectorStore.from_documents(documents, embeddings)\n",
        "\n",
        "    # 3. Extract and store graph\n",
        "    llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "    graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "    store_graph_documents(graph_documents)\n",
        "\n",
        "    # 4. Create RAG chain\n",
        "    chain = create_rag_chain(vector_store)\n",
        "\n",
        "    print(\"GraphRAG system ready\")\n",
        "    return chain\n",
        "if __name__ == \"__main__\":\n",
        "    chain = main()\n",
        "    #Test the system\n",
        "    test_graphrag_system(chain)"
      ]
    }
  ]
}